networks:
  rest_bridge:

services:
  rest:
    image: apache/iceberg-rest-fixture:1.9.2
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - CATALOG_CATALOG__IMPL=org.apache.iceberg.jdbc.JdbcCatalog
      - CATALOG_URI=jdbc:sqlite:file:/tmp/iceberg_rest_mode=memory
      - CATALOG_WAREHOUSE=s3://icebergdata/demo
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000
    depends_on:
      - minio
    networks:
      rest_bridge:
    ports:
      - 8181:8181
    expose:
      - 8181

  minio:
    image: minio/minio:RELEASE.2025-05-24T17-08-30Z
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
      - MINIO_DEFAULT_BUCKETS=icebergdata
    hostname: icebergdata.minio
    networks:
      rest_bridge:
    ports:
      - 9000:9000
      - 9001:9001
    expose:
      - 9001
      - 9000
    command: ["server", "/data", "--console-address", ":9001"]

  mc:
    depends_on:
      - minio
    image: minio/mc:RELEASE.2025-05-21T01-59-54Z
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: >
      /bin/sh -c " until (/usr/bin/mc alias set minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done; /usr/bin/mc rm -r --force minio/icebergdata; /usr/bin/mc mb minio/icebergdata; /usr/bin/mc policy set public minio/icebergdata; tail -f /dev/null "
    networks:
      rest_bridge:

  spark:
    depends_on:
      - rest
      - minio
    image: apache/spark:3.5.6-java17
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - SPARK_HOME=/opt/spark
      - PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/spark/bin:/opt/spark/sbin
    user: root
    networks:
      rest_bridge:
    ports:
      - "15002:15002"
    healthcheck:
      test: netstat -ltn | grep -c 15002
      interval: 1s
      retries: 1200
    volumes:
      - ./spark:/spark-script
    entrypoint: [ "/spark-script/spark-connect-server.sh" ]